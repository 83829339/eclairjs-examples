
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    var SparkConf = require('eclairjs\/SparkConf');\n",
    "    var SparkContext = require('eclairjs\/SparkContext');\n",
    "    var sparkConf = new SparkConf().setAppName(\"JavaScript TokenizerExample\");\n",
    "    var sc = new SparkContext(sparkConf);\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var SQLContext = require('eclairjs\/sql\/SQLContext');\n",
    "    var RowFactory = require('eclairjs\/sql\/RowFactory');\n",
    "    var StructField = require('eclairjs\/sql\/types\/StructField');\n",
    "    var StructType = require('eclairjs\/sql\/types\/StructType');\n",
    "    var Metadata = require('eclairjs\/sql\/types\/Metadata');\n",
    "    var DataTypes = require('eclairjs\/sql\/types').DataTypes;\n",
    "    var Tokenizer = require('eclairjs\/ml\/feature\/Tokenizer');\n",
    "    var RegexTokenizer = require('eclairjs\/ml\/feature\/RegexTokenizer');\n",
    "\n",
    "    var sqlContext = new SQLContext(sc);\n",
    "\n",
    "    var jrdd = sc.parallelize([\n",
    "      RowFactory.create(0, \"Hi I heard about Spark\"),\n",
    "      RowFactory.create(1, \"I wish Java could use case classes\"),\n",
    "      RowFactory.create(2, \"Logistic,regression,models,are,neat\")\n",
    "    ]);\n",
    "\n",
    "    var schema = new StructType([\n",
    "      new StructField(\"label\", DataTypes.IntegerType, false, Metadata.empty()),\n",
    "      new StructField(\"sentence\", DataTypes.StringType, false, Metadata.empty())\n",
    "    ]);\n",
    "\n",
    "    var sentenceDataFrame = sqlContext.createDataFrame(jrdd, schema);\n",
    "\n",
    "    var tokenizer = new Tokenizer().setInputCol(\"sentence\").setOutputCol(\"words\");\n",
    "\n",
    "    var wordsDataFrame = tokenizer.transform(sentenceDataFrame);\n",
    "    var output=\"\";\n",
    "    var wordList=wordsDataFrame.select(\"words\", \"label\"). take(3);\n",
    "\n",
    "print(JSON.stringify(wordList))\n",
    "    for (var i=0;i<wordList.length;i++) {\n",
    "      var words = wordList[i].getList(0);\n",
    "      for (var inx=0;inx<words.size();inx++) output+=words.get(i) + \" \";\n",
    "      output+=\"\\n\";\n",
    "    }\n",
    "\n",
    "    var regexTokenizer = new RegexTokenizer()\n",
    "      .setInputCol(\"sentence\")\n",
    "      .setOutputCol(\"words\")\n",
    "      .setPattern(\"\\\\W\");  \/\/ alternatively .setPattern(\"\\\\w+\").setGaps(false);\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var result = output;\n",
    "\n",
    "    print(result);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $example off$\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    sc.stop();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}